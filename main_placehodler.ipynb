{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project ClearChoise Textile Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The aim of this project is to develop a pattern classifier. By inputting an image, the program will provide feedback on the pattern present in the photographed garment. Making mornings easier and more fun for those with visual impairments, helping them pick out their perfect outfit effortlessly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First model looks for flowers. flower_model_28-02-24.pt\n",
    "- Then an model for geometric patterns. geometric_24-03-04.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cpu'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is problem with yolo locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Flowermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m protobuf<=3.20.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\users\\emmel\\desktop\\clearchoise textile classifier\\env\\lib\\site-packages (3.20.1)\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per C:\\Users\\emmel\\Desktop\\yolov5\\requirements.txt\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5  v6.1-362-g731a2f8c Python-3.10.6 torch-2.2.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "yolo_path = \"C:/Users/emmel/Desktop/yolov5\"\n",
    "model_path = \"./Flower_model/flower_model_28-02-24.pt\"\n",
    "\n",
    "yolo_model = torch.hub.load(yolo_path, 'custom', path=model_path, source='local')\n",
    "yolo_model.conf = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Geometricmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometric_model_path = \"./geometric_model/geometric_24-03-04.h5\" \n",
    "\n",
    "geometric_model = tf.keras.models.load_model(geometric_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (64,64)\n",
    "\n",
    "class_labels = [\"check\", \n",
    "                \"stripe\", \n",
    "                \"dots\"\n",
    "]\n",
    "\n",
    "def load_and_preprocess_image(image_path, img_dim):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, img_dim)\n",
    "    img = img[:, :, np.newaxis]\n",
    "    img = img / 255\n",
    "    return np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [ \"./img_for_test/1.jpg\",\n",
    "                \"./img_for_test/8.jpg\",\n",
    "                \"./img_for_test/6.jpg\",\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./img_for_test/1.jpg\n",
      "Predicted pattern: Flowers\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "./img_for_test/8.jpg\n",
      "Predicted pattern: check\n",
      "./img_for_test/6.jpg\n",
      "Predicted pattern: Flowers\n"
     ]
    }
   ],
   "source": [
    "for img_path in img_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    yolo_result = yolo_model(img)\n",
    "    yolo_preds = yolo_result.pandas().xyxy[0]\n",
    "    \n",
    "    if len(yolo_preds) > 0:\n",
    "        #print(f\"{img_path}\\nFlowers found: {len(yolo_preds)} \\n\")\n",
    "        #yolo_result.show()\n",
    "        print(f\"{img_path}\\nPredicted pattern: Flowers\")\n",
    "    else:\n",
    "        img_preprocessed = load_and_preprocess_image(img_path, img_dim)\n",
    "        prediction = geometric_model.predict(img_preprocessed)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        predicted_probability = prediction[0, predicted_class]\n",
    "\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "\n",
    "        print(f\"{img_path}\\nPredicted pattern: {predicted_label}\")\n",
    "        #print(\"Predicted Probability: {:.2f}%\".format(predicted_probability * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
