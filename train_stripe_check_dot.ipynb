{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model for detection of geometric patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\emmel\\Desktop\\ClearChoise Textile Classifier\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (64,64)\n",
    "img_channelr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_img(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(folder_path): \n",
    "        if filename.endswith(\"jpg\"):\n",
    "            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, img_dim)\n",
    "            #img = img[:, :, np.newaxis]\n",
    "            img = np.expand(img, axis=-1)\n",
    "\n",
    "            label = int(filename.split(\"_\")[0])\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./img_sliced_and_tilted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_and_preprocess_img(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images / 255\n",
    "#images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_test_split(images, labels, test_sixe=0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train, num_classes = 3)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train_one_hot.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of img preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_train[254,:,:])\n",
    "print(y_train[254])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\emmel\\Desktop\\ClearChoise Textile Classifier\\env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\emmel\\Desktop\\ClearChoise Textile Classifier\\env\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(64,64,1)),\n",
    "    layers.Normalization(),\n",
    "    layers.Conv2D(16, (3, 3), activation='elu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), activation='elu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.15),\n",
    "    layers.Conv2D(64, (3, 3),activation='elu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3),activation='elu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.35),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='elu'),\n",
    "\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizati  (None, 64, 64, 1)         3         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 62, 62, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 31, 31, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163206 (637.53 KB)\n",
      "Trainable params: 163203 (637.51 KB)\n",
      "Non-trainable params: 3 (16.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate =  0.0001),       \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = \"val_loss\", patience=10, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train_one_hot,\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    validation_data=(x_test, y_test_one_hot),\n",
    "    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "#plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"\", \n",
    "                \"\", \n",
    "                \"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert class labels to class labels (no one-hot encoding)\n",
    "y_true_classes = y_test\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Create a nice figure\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.set(font_scale=1.2)  # Adjust font size for readability\n",
    "\n",
    "# Display the heatmap\n",
    "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap=\"Greens\", \n",
    "            xticklabels= class_labels,\n",
    "            yticklabels= class_labels,)\n",
    "\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"keras.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, target_height, target_width):\n",
    "    img = cv2.resize(image, (target_width, target_height))\n",
    "    img = img.reshape((1, target_height, target_width, 1))  # Reshape to match model input shape\n",
    "    return img\n",
    "\n",
    "# def preprocess_image(image, target_height, target_width):\n",
    "#     img = cv2.resize(image, target_height, target_width)\n",
    "#     img = np.expand_dims(img, axis=-1)# Reshape to match model input shape\n",
    "#     return img\n",
    "\n",
    "\n",
    "\n",
    "def predict_from_image(test_image_preprocessed, model, class_labels):\n",
    "    prediction = model.predict(test_image_preprocessed)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    predicted_probability = prediction[0, predicted_class]\n",
    "\n",
    "    # Get the corresponding label for the predicted class\n",
    "    predicted_label = class_labels[predicted_class]\n",
    "\n",
    "    print(\"Prediction probabilities:\")\n",
    "    print(prediction)\n",
    "    print(\"\\nPredicted class:\", predicted_class)\n",
    "    print(\"Predicted Label:\", predicted_label)\n",
    "    print(\"Predicted Probability: {:.2f}%\".format(predicted_probability * 100))\n",
    "    print(predicted_probability)\n",
    "\n",
    "    return predicted_class, predicted_label, predicted_probability\n",
    "\n",
    "def test_images(image_paths, model, class_labels, target_height, target_width):\n",
    "    for image_path in image_paths:\n",
    "        # Load and preprocess the image\n",
    "        test_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "        test_image_preprocessed = preprocess_image(test_image, target_height, target_width)\n",
    "\n",
    "        # Display the preprocessed image\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(test_image_preprocessed.squeeze(), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        # Predict from the preprocessed image\n",
    "        print(\"Image Path:\", image_path)\n",
    "        predicted_class, predicted_label, predicted_probability = predict_from_image(test_image_preprocessed, model, class_labels)\n",
    "        print(\"=\"*30)\n",
    "\n",
    "\n",
    "\n",
    "image_paths = [\n",
    "    \"C:/Users/Development/Desktop/Patterns/img_for_tests/0_1_slice_4.jpg\",\n",
    "    \"C:/Users/Development/Desktop/Patterns/img_for_tests/0_2_slice_1.jpg\",\n",
    "    \"C:/Users/Development/Desktop/Patterns/img_for_tests/1_2_slice_2.jpg\",\n",
    "    \"C:/Users/Development/Desktop/Patterns/img_for_tests/1_1_slice_3.jpg\",\n",
    "    \"C:/Users/Development/Desktop/Patterns/img_for_tests/3_1_slice_4.jpg\",\n",
    "    \"C:/Users/Development/Desktop/Patterns/img_for_tests/3_2_slice_4.jpg\",\n",
    "    \"C:/Users/Development/Desktop/Patterns/img_for_tests/3_3_slice_0.jpg\",\n",
    "    \"C:/Users/Development/Desktop/geometric_pattern/img_sliced_and_tilted/1_3_slice_83.jpg\"\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    img_preprocessed = cv2.resize(img, IMAGE_DIM)\n",
    "    img_preprocessed = np.expand_dims(img_preprocessed, axis=-1) \n",
    "\n",
    "    return img_preprocessed\n",
    "\n",
    "testing_images = []\n",
    "for image_path in image_paths:\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_preprocessed = preprocess_image(img)\n",
    "    testing_images.append(img_preprocessed)\n",
    "\n",
    "testing_images = np.array(testing_images) / 255.0 \n",
    "\n",
    "predictions = model.predict(testing_images)\n",
    "\n",
    "# Display the images, predictions, and prediction probabilities\n",
    "for i in range(len(image_paths)):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(testing_images[i].reshape(64, 64), cmap='gray')\n",
    "    predicted_class = np.argmax(predictions[i])\n",
    "    plt.title(f\"Predicted Class: {predicted_class} ({class_labels[predicted_class]})\")\n",
    "    plt.xlabel(\"Prediction Probabilities:\\n\" + \"\\n\".join([f\"{class_labels[j]}: {predictions[i][j]:.4f}\" for j in range(predictions.shape[1])]))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
