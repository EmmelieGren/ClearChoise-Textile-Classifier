{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project ClearChoise Textile Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The aim of this project is to develop a pattern classifier. By inputting an image, the program will provide feedback on the pattern present in the photographed garment. Making mornings easier and more fun for those with visual impairments, helping them pick out their perfect outfit effortlessly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model for flowers detection. flower_model_28-02-24.pt\n",
    "- Model for solid colors. pattern_model_24-03-06.h5\n",
    "- Model for jeans or not. jeans_model_24-03-06.h5\n",
    "- Model for geometric patterns. geometric_24-03-04.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cpu'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is problem with yolo locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Flowermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v6.1-362-g731a2f8c Python-3.10.6 torch-2.2.1+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "yolo_path = \"C:/Users/emmel/Desktop/yolov5\"\n",
    "model_path = \"./Flower_model/flower_model_14-03-24.pt\"\n",
    "\n",
    "\n",
    "yolo_model = torch.hub.load(yolo_path, 'custom', path=model_path, source='local')\n",
    "yolo_model.conf = 0.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Patterns or not model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_modelpath = \"./solid_color_models/pattern_model_24-03-14.h5\" \n",
    "\n",
    "patterns_model = tf.keras.models.load_model(patterns_modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Jeansmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeans_modelpath = \"./solid_color_models/jeans_model_24-03-06.h5\" \n",
    "\n",
    "jeans_model = tf.keras.models.load_model(jeans_modelpath)\n",
    "\n",
    "labels_jeans = [\"Not jeans\", \n",
    "                \"Jeans\", \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Geometricmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometric_modelpath = \"./geometric_model/geometric_24-03-27.h5\" \n",
    "\n",
    "geometric_model = tf.keras.models.load_model(geometric_modelpath)\n",
    "\n",
    "labels_geometric = [\"check\", \n",
    "                    \"stripe\", \n",
    "                    \"dots\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [ \"./img_for_test/stripe_1.jpg\",\n",
    "                \"./img_for_test/stripe_2.jpg\",\n",
    "                \"./img_for_test/stripe_3.jpg\",\n",
    "                \"./img_for_test/check_1.jpg\",\n",
    "                \"./img_for_test/check_2.jpg\",\n",
    "                \"./img_for_test/check_3.jpg\",\n",
    "                \"./img_for_test/check_4.jpg\",\n",
    "                \"./img_for_test/color_1.jpg\",\n",
    "                \"./img_for_test/color_2.jpg\",\n",
    "                \"./img_for_test/color_3.jpg\",\n",
    "                \"./img_for_test/dots_1.jpg\",\n",
    "                \"./img_for_test/dots_2.jpg\",\n",
    "                \"./img_for_test/flowers_1.jpg\",\n",
    "                \"./img_for_test/flowers_2.jpg\",\n",
    "                \"./img_for_test/flowers_3.jpeg\",\n",
    "                \"./img_for_test/flowers_4.jpg\",\n",
    "                \"./img_for_test/jeans_1.jpg\",\n",
    "                \"./img_for_test/jeans_2.jpg\",\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    img_dim = (64,64)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, img_dim)\n",
    "    img = img[:, :, np.newaxis]\n",
    "    img = img / 255\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "def predict_pattern_keras(img_preprocessed):\n",
    "    pred_pattern = patterns_model.predict(img_preprocessed)\n",
    "    pred_class_pattern = np.argmax(pred_pattern)\n",
    "\n",
    "    if pred_class_pattern == 1:  # solid color\n",
    "        predictions_jeans = jeans_model.predict(img_preprocessed)\n",
    "        predicted_class_jeans = np.argmax(predictions_jeans)\n",
    "        return labels_jeans[predicted_class_jeans]\n",
    "        \n",
    "    elif pred_class_pattern == 0:\n",
    "        pred_geometric = geometric_model.predict(img_preprocessed)\n",
    "        pred_class_geometric = np.argmax(pred_geometric)\n",
    "        return labels_geometric[pred_class_geometric]\n",
    "    else:\n",
    "        return \"Unknown Pattern\"\n",
    "\n",
    "# Function to predict pattern for images\n",
    "def predict_pattern_for_images(img_paths):\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        yolo_result = yolo_model(img)\n",
    "        yolo_preds = yolo_result.pandas().xyxy[0]\n",
    "        \n",
    "        if len(yolo_preds) > 0:\n",
    "            print(f\"{img_path}\\nPredicted pattern: Flowers\\n\")\n",
    "        else:\n",
    "            img_preprocessed = load_and_preprocess_image(img_path)\n",
    "            prediction = predict_pattern_keras(img_preprocessed)\n",
    "            print(f\"{img_path}\\nPredicted pattern: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "./img_for_test/stripe_1.jpg\n",
      "Predicted pattern: stripe\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "./img_for_test/stripe_2.jpg\n",
      "Predicted pattern: stripe\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "./img_for_test/stripe_3.jpg\n",
      "Predicted pattern: Jeans\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "./img_for_test/check_1.jpg\n",
      "Predicted pattern: check\n",
      "\n",
      "./img_for_test/check_2.jpg\n",
      "Predicted pattern: Flowers\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/check_3.jpg\n",
      "Predicted pattern: check\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./img_for_test/check_4.jpg\n",
      "Predicted pattern: stripe\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "./img_for_test/color_1.jpg\n",
      "Predicted pattern: Not jeans\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./img_for_test/color_2.jpg\n",
      "Predicted pattern: Not jeans\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./img_for_test/color_3.jpg\n",
      "Predicted pattern: Not jeans\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./img_for_test/dots_1.jpg\n",
      "Predicted pattern: dots\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/dots_2.jpg\n",
      "Predicted pattern: dots\n",
      "\n",
      "./img_for_test/flowers_1.jpg\n",
      "Predicted pattern: Flowers\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/flowers_2.jpg\n",
      "Predicted pattern: check\n",
      "\n",
      "./img_for_test/flowers_3.jpeg\n",
      "Predicted pattern: Flowers\n",
      "\n",
      "./img_for_test/flowers_4.jpg\n",
      "Predicted pattern: Flowers\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./img_for_test/jeans_1.jpg\n",
      "Predicted pattern: Jeans\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/jeans_2.jpg\n",
      "Predicted pattern: Jeans\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_pattern_for_images(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color names and their corresponding RGB values\n",
    "color_names = {\n",
    "    'black': (0, 0, 0),\n",
    "    'white': (255, 255, 255),\n",
    "    'red': (255, 0, 0),\n",
    "    'green': (0, 128, 0),\n",
    "    'blue': (0, 0, 255),\n",
    "    #'yellow': (255,255,204), #ljusgul\n",
    "    #'orange': (255,165,0),\n",
    "    #'purple': (153,50,204)\n",
    "}\n",
    "\n",
    "# Function to calculate color difference\n",
    "def color_difference(rgb1, rgb2):\n",
    "    rmean = (rgb1[0] + rgb2[0]) / 2\n",
    "    r = rgb1[0] - rgb2[0]\n",
    "    g = rgb1[1] - rgb2[1]\n",
    "    b = rgb1[2] - rgb2[2]\n",
    "    return np.sqrt((2 + rmean / 256) * r ** 2 + 4 * g ** 2 + (2 + (255 - rmean) / 256) * b ** 2)\n",
    "\n",
    "# Function to get the closest color\n",
    "def get_color_name(rgb_tuple):\n",
    "    closest_color_name = None\n",
    "    min_distance = float('inf')\n",
    "    for name, rgb in color_names.items():\n",
    "        distance = color_difference(rgb_tuple, rgb)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_color_name = name\n",
    "    return closest_color_name\n",
    "\n",
    "def output_color(img_paths):\n",
    "    image = cv2.cvtColor(cv2.imread(img_paths), cv2.COLOR_BGR2RGB)\n",
    "    unique_colors, counts = np.unique(image.reshape(-1, 3), axis=0, return_counts=True)\n",
    "    sorted_indices = np.argsort(counts)[::-1]\n",
    "    sorted_colors = unique_colors[sorted_indices]\n",
    "    top_color_names = [get_color_name(tuple(color)) for color in sorted_colors[:1]]\n",
    "    return top_color_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in img_paths:\n",
    "#     color = output_color(img) \n",
    "#     print (color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict pattern for images\n",
    "def predict_pattern_for_images(img_paths):\n",
    "    for img_path in img_paths:\n",
    "        img_color = output_color(img_path)\n",
    "        img = cv2.imread(img_path)\n",
    "        yolo_result = yolo_model(img)\n",
    "        yolo_preds = yolo_result.pandas().xyxy[0]\n",
    "        \n",
    "        if len(yolo_preds) > 0:\n",
    "            print(f\"{img_path}\\nPredicted pattern: Flowers\")\n",
    "            print(f\"In color: {img_color[0]}\\n\")\n",
    "        else:\n",
    "            img_preprocessed = load_and_preprocess_image(img_path)\n",
    "            prediction = predict_pattern_keras(img_preprocessed)\n",
    "            print(f\"{img_path}\\nPredicted pattern: {prediction}\")\n",
    "            print(f\"In color: {img_color[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/stripe_1.jpg\n",
      "Predicted pattern: stripe\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./img_for_test/stripe_2.jpg\n",
      "Predicted pattern: stripe\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "./img_for_test/stripe_3.jpg\n",
      "Predicted pattern: Jeans\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "./img_for_test/check_1.jpg\n",
      "Predicted pattern: check\n",
      "In color: white\n",
      "\n",
      "./img_for_test/check_2.jpg\n",
      "Predicted pattern: Flowers\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "./img_for_test/check_3.jpg\n",
      "Predicted pattern: check\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/check_4.jpg\n",
      "Predicted pattern: stripe\n",
      "In color: green\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/color_1.jpg\n",
      "Predicted pattern: Not jeans\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/color_2.jpg\n",
      "Predicted pattern: Not jeans\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "./img_for_test/color_3.jpg\n",
      "Predicted pattern: Not jeans\n",
      "In color: red\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "./img_for_test/dots_1.jpg\n",
      "Predicted pattern: dots\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/dots_2.jpg\n",
      "Predicted pattern: dots\n",
      "In color: blue\n",
      "\n",
      "./img_for_test/flowers_1.jpg\n",
      "Predicted pattern: Flowers\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "./img_for_test/flowers_2.jpg\n",
      "Predicted pattern: check\n",
      "In color: white\n",
      "\n",
      "./img_for_test/flowers_3.jpeg\n",
      "Predicted pattern: Flowers\n",
      "In color: white\n",
      "\n",
      "./img_for_test/flowers_4.jpg\n",
      "Predicted pattern: Flowers\n",
      "In color: white\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "./img_for_test/jeans_1.jpg\n",
      "Predicted pattern: Jeans\n",
      "In color: green\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "./img_for_test/jeans_2.jpg\n",
      "Predicted pattern: Jeans\n",
      "In color: black\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_pattern_for_images(img_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
